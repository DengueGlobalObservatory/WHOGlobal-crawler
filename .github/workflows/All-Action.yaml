name: Web crawling on Github Action
on:
  workflow_dispatch:
jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checking out repo
        uses: actions/checkout@v3
      - name: Setting up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12.3'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium
          pip install bs4
          pip install pandas
          pip install requests

        
      - name: Create Downloads directory
        run: mkdir -p ${{ github.workspace }}/Downloads
            
      # Step 2: Get the latest data and store it as a CSV
      - name: Fetch latest data
        run: |-        
          curl "https://raw.githubusercontent.com/ahyoung-lim/DengueCrawler/ac9bcccf6ece2e5ecdf3d66587bdd2488b4398a1/data/report_date.csv" -o report_date.csv
              
      - name: Running the Python script
        run: python scraper/All-job.py
        
      - name: Commit and Push The Results From Python Selenium Action
        run: |
         git config --global user.name "github-actions[bot]"
         git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
         git add -A
         timestamp=$(date -u)
         git commit -m "Latest data: ${timestamp}" || exit 0
         git push

        